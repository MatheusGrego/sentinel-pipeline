# Sentinel Pipeline üõ∞Ô∏è

![Java](https://img.shields.io/badge/Java-17+-orange?style=for-the-badge&logo=openjdk)
![Spring Boot](https://img.shields.io/badge/Spring_Boot-3.x-6DB33F?style=for-the-badge&logo=spring)
![Docker](https://img.shields.io/badge/Docker-20.10+-2496ED?style=for-the-badge&logo=docker)
![AWS](https://img.shields.io/badge/AWS_(LocalStack)-S3_&_SQS-232F3E?style=for-the-badge&logo=amazon-aws)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14+-336791?style=for-the-badge&logo=postgresql)

Um pipeline de processamento de imagens ass√≠ncrono, constru√≠do com uma arquitetura de microsservi√ßos para demonstrar habilidades em sistemas distribu√≠dos, nuvem e boas pr√°ticas de desenvolvimento backend.

## üìñ Sobre o Projeto

O Sentinel Pipeline √© um projeto de portf√≥lio que simula um sistema de an√°lise de imagens de sat√©lite. Ele foi projetado para ser um exemplo pr√°tico de uma arquitetura robusta, resiliente e escal√°vel, utilizando tecnologias amplamente requisitadas no mercado.

O fluxo principal consiste em receber uma imagem via API, armazen√°-la de forma segura e enfileirar uma tarefa de an√°lise que √© processada em background, de forma totalmente ass√≠ncrona e desacoplada.

## üèõÔ∏è Arquitetura

O diagrama abaixo ilustra os componentes do sistema e o fluxo de dados principal, desde a requisi√ß√£o do cliente at√© a persist√™ncia do resultado da an√°lise. A arquitetura foi desenhada para ser clara, com responsabilidades bem definidas para cada microsservi√ßo.

```mermaid
graph TD
    subgraph "Ambiente Externo"
        A[Cliente de API]
    end

    subgraph "Ecossistema de Servi√ßos"
        B[API Gateway]
        C[Service Discovery - Eureka]
        
        subgraph "Servi√ßos de Neg√≥cio"
            D[ingestion-service]
            E[analysis-service]
        end

        subgraph "Depend√™ncias"
             F[Banco de Dados - PostgreSQL]
        end
    end

    subgraph "Nuvem Local - LocalStack"
        G[AWS S3]
        H[AWS SQS]
    end

    A -- "(1) POST /api/ingestion/v1/images" --> B
    B <--> C
    B -- "(2) Roteia para" --> D
    
    D -- "(3) Salva imagem" --> G
    D -- "(4) Envia mensagem" --> H

    E -- "(5) Ouve a fila" --> H
    E -- "(6) L√™ imagem" --> G
    E -- "(7) Persiste resultado" --> F
```
üõ†Ô∏è Tecnologias Utilizadas

Linguagem: Java 17+
Framework Principal: Spring Boot 3
Microsservi√ßos: Spring Cloud Gateway, Spring Cloud (Eureka)
Comunica√ß√£o Ass√≠ncrona: Spring Cloud AWS SQS
Armazenamento de Objetos: Spring Cloud AWS S3
Banco de Dados: PostgreSQL
Containeriza√ß√£o: Docker & Docker Compose
Simulador de Nuvem: LocalStack

## üöÄ Como Executar

Para executar o projeto em sua m√°quina local, o processo √© bem simples. A √∫nica configura√ß√£o manual √© automatizada por um script Python.

### Pr√©-requisitos
* Git
* Java (JDK) 17 ou superior
* Docker e Docker Compose
* Python 3.8+ e Pip

### Passos para a Execu√ß√£o

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone A url do repo
    cd sentinel-pipeline
    ```

2.  **Suba todo o ambiente com Docker Compose:**
    Este comando ir√° construir e iniciar todos os cont√™ineres. Execute em um terminal e deixe-o rodando para manter os servi√ßos de p√©.
    ```bash
    docker-compose up --build
    ```
    Aguarde at√© que os logs se estabilizem.

3.  **Execute o script de configura√ß√£o do ambiente:**
    Abra um **novo terminal**. O script abaixo ir√° criar o bucket S3 e a fila SQS necess√°rios dentro do LocalStack.

    * **Instale a √∫nica depend√™ncia necess√°ria:**
        execute:
        ```bash
        pip install -r requirements.txt
        ```

    * **Rode o script de setup:**
        ```bash
        python setup_local_aws.py
        ```

Pronto! Seu ambiente est√° configurado e pronto para receber requisi√ß√µes.

<details>
<summary>Clique para ver o c√≥digo do script üêç: <code>setup_local_aws.py</code></summary>

```python
# setup_local_aws.py
import boto3
from botocore.exceptions import ClientError

# --- Configura√ß√£o ---
LOCALSTACK_ENDPOINT_URL = 'http://localhost:4566'
S3_BUCKET_NAME = 'satellite-images'
SQS_QUEUE_NAME = 'image-analysis-queue'
AWS_REGION = 'us-east-1' # Regi√£o padr√£o do LocalStack

# Clientes Boto3 apontando para o LocalStack
s3_client = boto3.client(
    's3',
    endpoint_url=LOCALSTACK_ENDPOINT_URL,
    region_name=AWS_REGION
)

sqs_client = boto3.client(
    'sqs',
    endpoint_url=LOCALSTACK_ENDPOINT_URL,
    region_name=AWS_REGION
)

def create_resources():
    """Cria o bucket S3 e a fila SQS se eles n√£o existirem."""
    print("--- Configurando recursos na nuvem local (LocalStack) ---")
    
    # Criar bucket S3
    try:
        s3_client.create_bucket(Bucket=S3_BUCKET_NAME)
        print(f"‚úÖ Bucket '{S3_BUCKET_NAME}' criado com sucesso.")
    except ClientError as e:
        if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou' or e.response['Error']['Code'] == 'BucketAlreadyExists':
            print(f"‚ÑπÔ∏è  Bucket '{S3_BUCKET_NAME}' j√° existe. Pulando.")
        else:
            print(f"‚ùå Erro inesperado ao criar bucket: {e}")
            raise e

    # Criar fila SQS
    try:
        sqs_client.create_queue(QueueName=SQS_QUEUE_NAME)
        print(f"‚úÖ Fila '{SQS_QUEUE_NAME}' criada com sucesso.")
    except ClientError as e:
        print(f"‚ÑπÔ∏è  Fila '{SQS_QUEUE_NAME}' provavelmente j√° existe ou ocorreu um erro. Pulando. Detalhe: {e}")


if __name__ == "__main__":
    print("üöÄ Iniciando script de configura√ß√£o de recursos... üöÄ")
    create_resources()
    print("\nüéâ Ambiente configurado com sucesso! üéâ")
```

üìù Status do Projeto
Status: ‰ºÅÁîª (Kikaku - Em Planejamento) - Pronto para iniciar o desenvolvimento!!
